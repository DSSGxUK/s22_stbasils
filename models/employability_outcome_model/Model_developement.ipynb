{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bf44c8",
   "metadata": {},
   "source": [
    "### NEET EET Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f40f0a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 254 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.0.0)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.8 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "Successfully installed imbalanced-learn-0.9.1 imblearn-0.0 scikit-learn-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e43ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d0383",
   "metadata": {},
   "source": [
    "## Load and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931a637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here\n"
     ]
    }
   ],
   "source": [
    "#All import go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "#Get and describe data\n",
    "path = '/home/workspace/files/aryan/data_files_raw/eet_neet.csv'\n",
    "df = pd.read_csv(path)\n",
    "###################################33\n",
    "# Fill the numeric values with nan with 0\n",
    "df['TotalDisabilty'] = df['TotalDisabilty'].fillna(0)\n",
    "df['TotalMentalHealth'] = df['TotalMentalHealth'].fillna(0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "470dbf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EET', 'NEET', nan, 'Not Known'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EET status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79c7142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here\n"
     ]
    }
   ],
   "source": [
    "## Here we will check the features which have some nan values data\n",
    "## make the list of features which has missing values\n",
    "#Printing the number of uique values in columns\n",
    "df = df.drop(['Client Number','Prev Accomodation','A2','B2', 'E2', 'F1', 'F3','H3',\n",
    "              'Ref_CN', 'Ref No', 'Service Type', 'Status',\n",
    "       'Area', 'Age at Start', 'Scheme','EET status'],1)\n",
    "for feature in df.columns:\n",
    "    print('Feature: {}    Missing: {}    Categories: {}'.format(feature,np.round(df[feature].isnull().mean(), 4),len(df[feature].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fca1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuslts here\n"
     ]
    }
   ],
   "source": [
    "df['Session per week'] = df['Num Sessions']/df['Num Weeks']\n",
    "df.rename(columns = {'Do They Have Any Medical Issues':'Medical Issue',\n",
    "                     'Is An Interpreter required':'Intrptr Reqd',\n",
    "                     'Does the YP have a local Connection':'Local Connection'}, inplace = True)\n",
    "df = df.drop(['Num Sessions','Num Weeks','Minutes per week','Economic Status','Local Connection','Intrptr Reqd','K1','A1','J1','D1','L1','E1','F2','Local Connection'],1)\n",
    "\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8da06aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Immigration Status\n",
    "df1 = df.copy(deep=True)\n",
    "\n",
    "vari = 'B1'\n",
    "df1[vari] = np.where(df1[vari]=='-','Don\\'t Know / Refused', df1[vari])\n",
    "\n",
    "vari = 'C1'\n",
    "df1[vari] = np.where(df1[vari]=='-',np.NaN, df1[vari])\n",
    "\n",
    "\n",
    "vari = 'G1'\n",
    "df1[vari] = np.where(df1[vari]=='-',np.NaN, df1[vari])\n",
    "\n",
    "vari = 'H1'\n",
    "df1[vari] = np.where(df1[vari]=='-',np.NaN, df1[vari])\n",
    "\n",
    "vari = 'I1'\n",
    "df1[vari] = np.where(df1[vari]=='-',np.NaN, df1[vari])\n",
    "\n",
    "vari = 'Nationality'\n",
    "series = pd.value_counts(df1[vari])\n",
    "mask = (series/series.sum() * 100).lt(1)\n",
    "# To replace df['column'] use np.where I.e \n",
    "df1[vari] = np.where(df1[vari].isin(series[mask].index),'fill',df1[vari])\n",
    "\n",
    "vari = 'Preferred Language'\n",
    "series = pd.value_counts(df1[vari])\n",
    "mask = (series/series.sum() * 100).lt(2)\n",
    "# To replace df['column'] use np.where I.e \n",
    "df1[vari] = np.where(df1[vari].isin(series[mask].index),'fill',df1[vari])\n",
    "\n",
    "vari = 'Marital Status'\n",
    "df1[vari] = np.where((df1[vari]=='Couple Expecting with Children') | (df1[vari]=='Married / Civil Partnership') |\n",
    "                     (df1[vari]=='Couple Expecting') |\n",
    "                     (df1[vari]=='Couple with children') |(df1[vari]=='Couple'),'C', df1[vari])\n",
    "\n",
    "vari = 'Religion'\n",
    "series = pd.value_counts(df1[vari])\n",
    "mask = (series/series.sum() * 100).lt(2)\n",
    "# To replace df['column'] use np.where I.e \n",
    "df1[vari] = np.where(df1[vari].isin(series[mask].index),'fill',df1[vari])\n",
    "\n",
    "\n",
    "one_categ_columns_with_nan = ['Medical Issue','G1','H1','I1']\n",
    "df1[one_categ_columns_with_nan] = df1[one_categ_columns_with_nan].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "388abbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the vaues\n",
    "df1['Time per Session'].fillna(df1['Time per Session'].mean(), inplace=True)\n",
    "df1['Session per week'].fillna(df1['Session per week'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a8645ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    824\n",
       "Positive    413\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccfce0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "######################################################################\n",
    "################# Conversion to Label Encoded Data ###################\n",
    "######################################################################\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['Medical Issue'] = le.fit_transform(df1['Medical Issue'])\n",
    "output = open('MedicalIssue.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['Initial'] = le.fit_transform(df1['Initial'])\n",
    "output = open('Initial.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['G1'] = le.fit_transform(df1['G1'])\n",
    "output = open('G1.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['H1'] = le.fit_transform(df1['H1'])\n",
    "output = open('H1.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['I1'] = le.fit_transform(df1['I1'])\n",
    "output = open('I1.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "# At the last, encode the result variable\n",
    "le = LabelEncoder()\n",
    "df1['Result'] = le.fit_transform(df1['Result'].values)\n",
    "output = open('Result.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()\n",
    "\n",
    "#Separate training features from target\n",
    "X = df1.drop(['Result'], axis=1)\n",
    "y = df1['Result']\n",
    "\n",
    "#######################################\n",
    "######## Train dataset = X ############\n",
    "######## Test Dataset = y  ############\n",
    "#######################################\n",
    "\n",
    "######################################################################\n",
    "################### Standard scaling numeric data ####################\n",
    "######################################################################\n",
    "\n",
    "ss = StandardScaler()\n",
    "X[['Session per week','TotalDisabilty','TotalMentalHealth','Time per Session']] = ss.fit_transform(X[['Session per week','TotalDisabilty','TotalMentalHealth','Time per Session']])\n",
    "output = open('StandardScaler.pkl', 'wb')\n",
    "pickle.dump(ss, output)\n",
    "output.close()\n",
    "\n",
    "\n",
    "######################################################################\n",
    "################### One Hot Encoding Category data ###################\n",
    "######################################################################\n",
    "\n",
    "categ = ['Gender','Preferred Language','Nationality','B1','C1','Marital Status','Sexual Orientation','Religion']\n",
    "ohe = OneHotEncoder()\n",
    "X_object = X[categ]\n",
    "X = X.drop(categ,1)\n",
    "ohe.fit(X_object)\n",
    "codes = ohe.transform(X_object).toarray()\n",
    "feature_names = ohe.get_feature_names(categ)\n",
    "X = pd.concat([X,  pd.DataFrame(codes,columns=feature_names).astype(int)], axis=1)\n",
    "\n",
    "output = open('OneHotEncoder.pkl', 'wb')\n",
    "pickle.dump(ohe, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c086651",
   "metadata": {},
   "source": [
    "## train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "609c6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now split the data into train and test Split \n",
    "seed = 999\n",
    "X_Train, X_val, y_Train, y_val = train_test_split(X, y, stratify = y, test_size = 0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd23fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Tets data are :\n",
      "(989, 50)\n",
      "(248, 50)\n",
      "Teh ditribution of teh train data is :\n",
      "0    659\n",
      "1    330\n",
      "Name: Result, dtype: int64\n",
      "Teh ditribution of teh test data is :\n",
      "0    165\n",
      "1     83\n",
      "Name: Result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Tets data are :\")\n",
    "print(X_Train.shape)\n",
    "print(X_val.shape)\n",
    "print(\"Teh ditribution of teh train data is :\")\n",
    "print(y_Train.value_counts())\n",
    "print(\"Teh ditribution of teh test data is :\")\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a29364",
   "metadata": {},
   "source": [
    "## Augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a0124ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    659\n",
       "1    659\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Borderline SMotre with SVM\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "oversample = SVMSMOTE()\n",
    "X1, y1 = oversample.fit_resample(X_Train, y_Train)\n",
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7ea1c",
   "metadata": {},
   "source": [
    "## Grid Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1798f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.606, F1_macro=0.586 est=0.595, cfg={'class_weight': 'balanced', 'max_depth': 7, 'n_estimators': 120}\n",
      ">acc=0.677, F1_macro=0.610 est=0.596, cfg={'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 120}\n",
      ">acc=0.626, F1_macro=0.599 est=0.596, cfg={'class_weight': 'balanced', 'max_depth': 7, 'n_estimators': 120}\n",
      ">acc=0.535, F1_macro=0.509 est=0.604, cfg={'class_weight': 'balanced', 'max_depth': 7, 'n_estimators': 100}\n",
      ">acc=0.646, F1_macro=0.616 est=0.589, cfg={'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 120}\n",
      ">acc=0.667, F1_macro=0.646 est=0.602, cfg={'class_weight': 'balanced', 'max_depth': 7, 'n_estimators': 60}\n",
      ">acc=0.636, F1_macro=0.602 est=0.605, cfg={'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 60}\n",
      ">acc=0.646, F1_macro=0.605 est=0.594, cfg={'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 120}\n",
      ">acc=0.616, F1_macro=0.585 est=0.601, cfg={'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 120}\n",
      ">acc=0.551, F1_macro=0.517 est=0.620, cfg={'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 80}\n",
      "Accuracy: 0.621 (0.044)\n",
      "F1_macro: 0.587 (0.041)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "outer_results_f1 = list()\n",
    "for (i,(train_index, test_index)) in enumerate(cv_outer.split(X_Train,y_Train)):\n",
    "    # split data\n",
    "    X_train_outer, X_test_outer = X_Train.iloc[train_index], X_Train.iloc[test_index]\n",
    "    y_train_outer, y_test_outer = y_Train.iloc[train_index], y_Train.iloc[test_index]\n",
    "    \n",
    "    # configure the cross-validation procedure\n",
    "    cv_inner = StratifiedKFold(n_splits=8, shuffle=True, random_state=1)\n",
    "    # define the model\n",
    "    model = RandomForestClassifier(criterion='log_loss',random_state=1)\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['n_estimators'] = [60,80,100,120]\n",
    "    #space['min_samples_split'] = [10,20,28]\n",
    "    space['max_depth'] = [5,6,7]\n",
    "    space['class_weight'] = ['balanced', None]\n",
    "    \n",
    "    # define search\n",
    "    search = GridSearchCV(model, space, scoring='f1_macro', cv=cv_inner)\n",
    "    # execute search\n",
    "    result = search.fit(X_train_outer, y_train_outer)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test_outer)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test_outer, yhat)\n",
    "    acc_f1=f1_score(y_test_outer, yhat, average='macro')\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    outer_results_f1.append(acc_f1)\n",
    "    \n",
    "    # report progress\n",
    "    print('>acc=%.3f, F1_macro=%.3f est=%.3f, cfg=%s' % (acc, acc_f1, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))\n",
    "print('F1_macro: %.3f (%.3f)' % (np.mean(outer_results_f1), np.std(outer_results_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b8bd808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Threshold Tuning, results are:\n",
      "\n",
      "F1_macro:0.622 Threshold=0.43\n",
      "\n",
      "\n",
      "\n",
      "The confusion matrix for maxium score is :\n",
      "[[144  21]\n",
      " [ 53  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80       165\n",
      "           1       0.59      0.36      0.45        83\n",
      "\n",
      "    accuracy                           0.70       248\n",
      "   macro avg       0.66      0.62      0.62       248\n",
      "weighted avg       0.68      0.70      0.68       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#'class_weight': {0: 0.7, 1: 0.3}, 'max_depth': 8, 'n_estimators': 60\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "best_model = RandomForestClassifier(max_depth = 6, n_estimators=60)\n",
    "best_model = best_model.fit(X_Train,y_Train)\n",
    "# Do the Threshold tunign and check for the possible result we can get at any threshold\n",
    "yhat = best_model.predict_proba(X_val)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:,1]\n",
    "# define thresholds\n",
    "thresholds = np.arange(0, 1, 0.001)\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_val, to_labels(probs, t), average='macro') for t in thresholds]\n",
    "\n",
    "# get best threshold\n",
    "ix = np.argmax(scores)\n",
    "\n",
    "max_score_on_val = scores[ix]\n",
    "#final_model_RF = model\n",
    "y_pred = np.zeros((len(X_val),1), np.uint8)\n",
    "for j in range(len(X_val)):\n",
    "    y_pred[j] = to_labels(probs[j], thresholds[ix])\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "print(\"After Threshold Tuning, results are:\\n\")\n",
    "print('F1_macro:%.3f Threshold=%.2f' % (scores[ix],thresholds[ix]))\n",
    "print(\"\\n\\n\")\n",
    "print(\"The confusion matrix for maxium score is :\")\n",
    "print(confusion)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "13fba0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving teh model to teh pickle file \n",
    "import pickle\n",
    "\n",
    "# Thresh is 0.43\n",
    "output = open('model.pkl', 'wb')\n",
    "pickle.dump(best_model, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78097a",
   "metadata": {},
   "source": [
    "## Visualize the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5be218bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 527 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90076ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree here !\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "data = plot_tree(best_model.estimators_[1], \n",
    "          feature_names=X.columns,\n",
    "          class_names=['0','1'], \n",
    "          filled=True, impurity=True, \n",
    "          rounded=True)\n",
    "#fig.savefig('2224_mod_ADAsyn_RF.png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bced72a",
   "metadata": {},
   "source": [
    "## Explanations for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c5d39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_unclustered = best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "951e572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features :\n",
      "50\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Initial', 'Medical Issue', 'G1', 'H1', 'I1', 'TotalDisabilty',\n",
       "       'TotalMentalHealth', 'Time per Session', 'Session per week',\n",
       "       'Gender_Female', 'Gender_Male', 'Gender_Trans_Gender',\n",
       "       'Gender_nan', 'Preferred Language_** Believed to be English',\n",
       "       'Preferred Language_** English', 'Preferred Language_fill',\n",
       "       'Preferred Language_nan', 'Nationality_Non-EEA country national',\n",
       "       'Nationality_Other EEA country national',\n",
       "       'Nationality_UK National Resident in UK', 'Nationality_fill',\n",
       "       'Nationality_nan', \"B1_Don't Know / Refused\", 'B1_Housing Benefit',\n",
       "       'B1_No benefits', 'B1_Universal Credit', 'B1_nan',\n",
       "       'C1_N/A - Not Applicable', 'C1_No', 'C1_Yes', 'C1_nan',\n",
       "       'Marital Status_C', 'Marital Status_Other',\n",
       "       'Marital Status_Single', 'Marital Status_Single Lone Parent',\n",
       "       'Marital Status_Single Pregnant', 'Marital Status_nan',\n",
       "       'Sexual Orientation_Bisexual', 'Sexual Orientation_Gay or Lesbian',\n",
       "       'Sexual Orientation_Heterosexual or Straight',\n",
       "       'Sexual Orientation_Other', 'Sexual Orientation_Refused to answer',\n",
       "       'Sexual Orientation_nan', 'Religion_Christian - Other',\n",
       "       'Religion_Muslim', 'Religion_No Religion',\n",
       "       'Religion_Refused to answer', 'Religion_Roman Catholic',\n",
       "       'Religion_fill', 'Religion_nan'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total features :\")\n",
    "print(len(best_model.feature_names_in_))\n",
    "print('\\n')\n",
    "best_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fef0646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############for the Data 2224\n",
    "\n",
    "columns = ['Initial', 'Medical Issue', 'G1', 'H1', 'I1',\n",
    "       'TotalDisabilty', 'TotalMentalHealth', 'Time per Session',\n",
    "       'Session per week', 'Gender','Preferred Language', 'Nationality', 'B1',\n",
    "       'C1','Marital Status','Sexual Orientation', 'Religion']\n",
    "\n",
    "one_categ_columns = ['Initial','Medical Issue','Local Connection','Intrptr Reqd','A1','D1','E1','G1','F2','H1','J1','L1','I1','TotalDisabilty',\n",
    "       'TotalMentalHealth', 'Time per Session','Session per week']\n",
    "\n",
    "pointer = 0\n",
    "importances = []\n",
    "for cat in columns:\n",
    "    if(cat in one_categ_columns):\n",
    "        values = 1\n",
    "    else:\n",
    "        values = len(df1[cat].unique())\n",
    "    importance = sum(importances_unclustered[pointer:(pointer+values)])\n",
    "    importances.append(importance)\n",
    "    pointer=pointer+values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c55fbf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features detected are 50 with feature importance sum 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total features detected are {} with feature importance sum {}\".format(pointer, sum(importances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd67379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanations here!\n"
     ]
    }
   ],
   "source": [
    "forest_importances = pd.Series(importances, index=columns)\n",
    "forest_importances = forest_importances.sort_values()\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.barh(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "plot_width, plot_height = (24,18)\n",
    "plt.rcParams['figure.figsize'] = (plot_width,plot_height)\n",
    "plt.rcParams['font.size']=22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b333d2b",
   "metadata": {},
   "source": [
    "### Calculate the confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64b693",
   "metadata": {},
   "source": [
    "Value of z = 1.64 (90%)\n",
    "1.96 (95%)\n",
    "2.33 (98%)\n",
    "2.58 (99%)\n",
    "\n",
    "interval = z * sqrt( (accuracy * (1 - accuracy)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87e353ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model was 0.72 +/- 0.05588245728543139 at the 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# 95% Confidence interval\n",
    "acc=0.72\n",
    "interval = 1.96 * np.sqrt((acc * (1-acc))/248)\n",
    "print(\"The accuracy of the model was {} +/- {} at the 95% confidence level.\".format(acc,interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76d36dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model was 0.72 +/- 0.0664316966709465 at the 98% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# 98% Confidence interval\n",
    "acc=0.72\n",
    "interval = 2.33 * np.sqrt((acc * (1-acc))/248)\n",
    "print(\"The accuracy of the model was {} +/- {} at the 98% confidence level.\".format(acc,interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7deb7",
   "metadata": {},
   "source": [
    "## Temporary Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3fa3fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "######################################################################\n",
    "################# Conversion to Label Encoded Data ###################\n",
    "######################################################################\n",
    "\n",
    "#columns = ['Initial', 'Medical Issue', 'Intrptr Reqd', 'Local Connection',\n",
    "#       'A1', 'D1', 'E1', 'F2', 'G1', 'H1', 'I1', 'J1', 'L1',\n",
    "#       'TotalDisabilty', 'TotalMentalHealth', 'Time per Session',\n",
    "#       'Session per week', 'Gender','Preferred Language', 'Nationality', 'B1',\n",
    "#       'C1','Marital Status','Sexual Orientation', 'Religion']\n",
    "\n",
    "def transform_input(x):\n",
    "    transformed = []\n",
    "    \n",
    "    # Label transform the data \n",
    "    \n",
    "    output = open('Initial.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['Initial']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('MedicalIssue.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['Medical Issue']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('Intrptr Reqd.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['Intrptr Reqd']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('Local Connection.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['Local Connection']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('A1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['A1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('D1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['D1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('E1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['E1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('F2.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['F2']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('G1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['G1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('H1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['H1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('I1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['I1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('J1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['J1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    output = open('L1.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([x['L1']])\n",
    "    transformed.append(a[0])\n",
    "    \n",
    "    # Standard Scale the data\n",
    "    output = open('StandardScaler.pkl', 'rb')\n",
    "    le = pickle.load(output)\n",
    "    output.close()\n",
    "    a = le.transform([[x['TotalDisabilty'],x['TotalMentalHealth'],x['Time per Session'],x['Session per week']]])\n",
    "    transformed.append(a[0][0])\n",
    "    transformed.append(a[0][1])\n",
    "    transformed.append(a[0][2])\n",
    "    transformed.append(a[0][3])\n",
    "    transformed = np.asarray(transformed)\n",
    "    \n",
    "    #One hot encoding the data finally\n",
    "    output = open('OneHotEncoder.pkl', 'rb')\n",
    "    ohe = pickle.load(output)\n",
    "    output.close()\n",
    "    codes = ohe.transform([[x['Gender'],x['Preferred Language'],x['Nationality'],x['B1'],x['C1'],x['Marital Status'],x['Sexual Orientation'],x['Religion']]]).toarray()\n",
    "    transformed = np.append(transformed,codes[0])\n",
    "    transformed = np.reshape(transformed,(1,58))\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54c26e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing one positive and one negative case to judge effect \n",
    "testp = df1[0:].to_dict(orient='records')[0]\n",
    "testn = df1[1:].to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1bf3e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56346071 0.43653929]]\n",
      "[[0.6424672 0.3575328]]\n"
     ]
    }
   ],
   "source": [
    "transformedp = transform_input(testp)\n",
    "transformedn = transform_input(testn)\n",
    "# >0.4 a positive\n",
    "# <0.4 a negative\n",
    "print(best_model.predict_proba(transformedp))\n",
    "print(best_model.predict_proba(transformedn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "94b7cf43",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1237.000000\n",
       "mean        2.604746\n",
       "std         1.490144\n",
       "min         1.000000\n",
       "25%         2.083333\n",
       "50%         2.312500\n",
       "75%         2.500000\n",
       "max        17.500000\n",
       "Name: Session per week, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Session per week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea15d8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.38095238095238"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp['Time per Session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a25e63fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp['Session per week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a92f6cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session per week are 1.5\n",
      "Session per week 0.0 predicted [[0.52054455 0.47945545]]\n",
      "Session per week 1.0 predicted [[0.53571172 0.46428828]]\n",
      "Session per week 2.0 predicted [[0.5450664 0.4549336]]\n",
      "Session per week 3.0 predicted [[0.54571965 0.45428035]]\n",
      "Session per week 4.0 predicted [[0.53666394 0.46333606]]\n",
      "Session per week 5.0 predicted [[0.54499728 0.45500272]]\n",
      "Session per week 6.0 predicted [[0.54792035 0.45207965]]\n",
      "Session per week 7.0 predicted [[0.55181636 0.44818364]]\n",
      "Session per week 8.0 predicted [[0.55181636 0.44818364]]\n",
      "Session per week 9.0 predicted [[0.56669732 0.43330268]]\n"
     ]
    }
   ],
   "source": [
    "print('Session per week are {}'.format(testp['Session per week']))\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "#Sesion per week and Time per session are interchanged\n",
    "# cHECK THE EFFECT OF THEM ON BOTH THE DATASETS\n",
    "for i in np.arange(0.0,10.00,0.5):\n",
    "    test1 = testp.copy()\n",
    "    test1['Time per Session'] = i\n",
    "    transformed = transform_input(test1)\n",
    "    print(\"Session per week {} predicted {}\".format(i,best_model.predict_proba(transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e454762c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84/770471970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in df1['B1'].unique():\n",
    "    test1 = test.copy()\n",
    "    test1['B1'] = i\n",
    "    transformed = transform_input(test1)\n",
    "    print(i)\n",
    "    print(best_model.predict_proba(transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d1249301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A - Not Applicable\n",
      "[[0.48238204 0.51761796]]\n",
      "No\n",
      "[[0.50622681 0.49377319]]\n",
      "nan\n",
      "[[0.49274237 0.50725763]]\n",
      "Yes\n",
      "[[0.54207619 0.45792381]]\n"
     ]
    }
   ],
   "source": [
    "for i in df1['C1'].unique():\n",
    "    test1 = test.copy()\n",
    "    test1['C1'] = i\n",
    "    transformed = transform_input(test1)\n",
    "    print(i)\n",
    "    print(best_model.predict_proba(transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ddfc6341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK National Resident in UK\n",
      "[[0.48238204 0.51761796]]\n",
      "nan\n",
      "[[0.48891763 0.51108237]]\n",
      "Non-EEA country national\n",
      "[[0.4239236 0.5760764]]\n",
      "Other EEA country national\n",
      "[[0.49857234 0.50142766]]\n",
      "fill\n",
      "[[0.48373828 0.51626172]]\n"
     ]
    }
   ],
   "source": [
    "for i in df1['Nationality'].unique():\n",
    "    test1 = test.copy()\n",
    "    test1['Nationality'] = i\n",
    "    transformed = transform_input(test1)\n",
    "    print(i)\n",
    "    print(best_model.predict_proba(transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b43d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
