{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae5a265",
   "metadata": {},
   "source": [
    "### EET to Neet data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e818ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here\n"
     ]
    }
   ],
   "source": [
    "# Load the data for analysis\n",
    "#All import go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Get and describe data\n",
    "path = '/home/workspace/files/aryan/data_files_raw/diversity_changes/Economic Status.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.sort_values(['Client Number'])\n",
    "#df = df.drop(['Minutes Total','Num Sessions','Num Weeks','Minutes per week'],1)\n",
    "#df.rename(columns = {'Do ':'Full Assessment'}, inplace = True)\n",
    "df\n",
    "###################################\n",
    "# Fill the numeric values with nan with 0\n",
    "#df['TotalDisabilty'] = df['TotalDisabilty'].fillna(0)\n",
    "#df['TotalMentalHealth'] = df['TotalMentalHealth'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6c5f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !!\n"
     ]
    }
   ],
   "source": [
    "# Take the data from Economic Codes\n",
    "# Merge them with the data of the clients \n",
    "path = '/home/workspace/files/aryan/data_files_raw/diversity_changes/Economic Codes.csv'\n",
    "df1 = pd.read_csv(path)\n",
    "df = pd.merge(df,df1,how=\"left\",\n",
    "                      left_on='Economic Status',\n",
    "              right_on='Description',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "df=df.drop(['Code','Economic Status','EET Detail','Description'],1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757643cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !!\n"
     ]
    }
   ],
   "source": [
    "# Now club them with the client numbers\n",
    "df['Num Entries'] = df.groupby('Client Number')['Client Number'].transform('count')\n",
    "df = df[df['Num Entries']>1]\n",
    "df = df[df['EET status']!='Not Known']\n",
    "df = df.sort_values(['Client Number','Until'])\n",
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1a2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out teh final result of the neet or the eet status\n",
    "df_final = df.drop_duplicates(subset=['Client Number'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b20bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !\n"
     ]
    }
   ],
   "source": [
    "# Now drop the matching columns to make sure that the last occurences are reoveed\n",
    "df_upper_occurences = pd.concat([df, df_final])\n",
    "df_upper_occurences = df_upper_occurences.drop_duplicates(keep=False)\n",
    "df_upper_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39801a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find if teh NEET exists in the resulting upper occurences\n",
    "# The Existsg column will containt the occurences of the NEET in the finbal column \n",
    "# Neet presence will give it a True or it will a false\n",
    "g = df_upper_occurences.groupby('Client Number')\n",
    "df_upper_occurences['Exists'] = g['EET status'].transform(lambda x: 'NEET' if (x.eq('NEET').any()) else 'EET' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b0136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_upper_occurences.replace(True,'NEET', inplace=True)\n",
    "#df_upper_occurences.replace(False,'EET', inplace = True)\n",
    "df_initial = df_upper_occurences.drop_duplicates(subset=['Client Number'], keep='first')\n",
    "\n",
    "# Droping the other rows from the database\n",
    "# keep the only intial rows of teh data \n",
    "df_intial = df_initial.drop(['Until','EET status','Num Entries'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58773e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(['Until','Num Entries'],1)\n",
    "df_final = df_final.rename(columns={'EET status':'Final'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecbe94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data here!\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df_initial,df_final,how=\"left\",\n",
    "                      on='Client Number',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6271e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data here !\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Until','EET status','Num Entries'],1)\n",
    "df = df.rename(columns={'Exists':'Initial'})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775bbdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !1\n"
     ]
    }
   ],
   "source": [
    "### Now just use this to determine the FInal Outcome \n",
    "# Neet -> eet      +ve\n",
    "# eet -> eet       +ve\n",
    "# eet -> neet      -ve\n",
    "# neet -> neet     -ve\n",
    "\n",
    "df1 = df.copy(deep=True)\n",
    "\n",
    "def result(row):\n",
    "    if (row.Initial=='NEET') and(row.Final=='EET') :\n",
    "        return \"Positive\"\n",
    "    elif (row.Initial=='EET') and(row.Final=='EET'):\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "df1 = df1.assign(Result=df1.apply(result, axis=1))\n",
    "\n",
    "df1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6600a032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    824\n",
       "Positive    413\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af07e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just take the initial part that is oign to be used in tthe Development of the model\n",
    "df1 = df1.drop(['Final'],1)\n",
    "df1.to_csv('/home/workspace/files/aryan/data_files_raw/diversity_changes/eet_neet_outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e12d2",
   "metadata": {},
   "source": [
    "## Check the Max rows we can get from different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29049350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !\n"
     ]
    }
   ],
   "source": [
    "#Loading teh diversity dataset\n",
    "path = '/home/workspace/files/aryan/data_files_raw/diversity_changes/eet_neet_outputs.csv'\n",
    "eet_neet = pd.read_csv(path)\n",
    "eet_neet = eet_neet.sort_values(by=['Client Number'])\n",
    "print(eet_neet.shape)\n",
    "eet_neet.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026c2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !\n"
     ]
    }
   ],
   "source": [
    "#Loading teh diversity dataset\n",
    "path = '/home/workspace/files/stbasil_prj/org_data/YP Background_with_MH_Disability.csv'\n",
    "yp_back1 = pd.read_csv(path)\n",
    "yp_back1 = yp_back1.sort_values(by=['Client Number'])\n",
    "yp_back1 = yp_back1[['Client Number','TotalDisabilty','TotalMentalHealth']]\n",
    "yp_back1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f602ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !\n"
     ]
    }
   ],
   "source": [
    "# Merge the medication and the alergies with the dat \n",
    "path = '/home/workspace/files/aryan/data_files_raw/yp_background.csv'\n",
    "yp_back = pd.read_csv(path)\n",
    "yp_back = yp_back.sort_values(by=['Client Number'])\n",
    "yp_back = pd.merge(yp_back,yp_back1,how=\"left\",\n",
    "                      on='Client Number',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "print(yp_back.shape)\n",
    "yp_back.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f93ed2",
   "metadata": {},
   "source": [
    "### check with the Yp Backgorund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcadd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data here\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(eet_neet,yp_back,how=\"left\",\n",
    "                      on='Client Number',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "#df= df[df['Result'].notnull()]\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce6341",
   "metadata": {},
   "source": [
    "## Check with Diversity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb890020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here\n"
     ]
    }
   ],
   "source": [
    "# Merge the medication and the alergies with the dat \n",
    "path = '/home/workspace/files/aryan/data_files_raw/diversity_changes/merged_without_null_rows.csv'\n",
    "merged = pd.read_csv(path)\n",
    "print(merged.shape)\n",
    "merged = merged.drop_duplicates(subset=['Client Number'], keep='first')\n",
    "df1 = pd.merge(df,merged,how=\"left\",on='Client Number')\n",
    "print(df1.shape)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977b785",
   "metadata": {},
   "source": [
    "## Check with Support hrs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f60e60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuslts here\n"
     ]
    }
   ],
   "source": [
    "#Now load and check the Support hrs dataset\n",
    "path = '/home/workspace/files/aryan/data_files_raw/Support_modified.csv'\n",
    "support_hrs = pd.read_csv(path)\n",
    "print(support_hrs.shape)\n",
    "support_hrs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a1f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results here!\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1,support_hrs,how=\"left\",\n",
    "                      left_on='Client Number',\n",
    "              right_on='Client No',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "#df= df[df['Result'].notnull()]\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d548da73",
   "metadata": {},
   "source": [
    "## Check withTenants dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d95519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here !\n"
     ]
    }
   ],
   "source": [
    "#Now load and check the Support hrs dataset\n",
    "path = '/home/workspace/files/aryan/data_files_raw/Tenants.csv'\n",
    "tenants = pd.read_csv(path)\n",
    "print(tenants.shape)\n",
    "tenants = tenants.drop_duplicates(subset=['Client Number'], keep='last')\n",
    "print(tenants.shape)\n",
    "tenants.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e349059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df,tenants,how=\"left\",\n",
    "                      on='Client Number',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "#df= df[df['Result'].notnull()]\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa468f",
   "metadata": {},
   "source": [
    "## Check for Life skills program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e712b5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here \n"
     ]
    }
   ],
   "source": [
    "#Now load and check the Support hrs dataset\n",
    "path = '/home/workspace/files/aryan/data_files_raw/Life Skills.csv'\n",
    "life = pd.read_csv(path)\n",
    "print(life.shape)\n",
    "life = life.drop_duplicates(subset=['Client Number'], keep='last')\n",
    "print(life.shape)\n",
    "life.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e988d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df,life,how=\"left\",\n",
    "                      on='Client Number',\n",
    "                      left_index=False,\n",
    "                      right_index=False,\n",
    "                      sort=False,\n",
    "                      suffixes=(\"_x\", \"_y\"),\n",
    "                      copy=True,\n",
    "                      indicator=False,\n",
    "                      validate=None,\n",
    "                     )\n",
    "#df= df[df['Result'].notnull()]\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b4758",
   "metadata": {},
   "source": [
    "### Check for whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "333df29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(['Salary/Income', 'Immigration Status/Eligibility Reason','Please List any Medications/Allergies',\n",
    "       'Communication/Language Barriers',\n",
    "       'Mental Health/Learning Disabilities', \n",
    "       'If current accommodation is not the main applicants last settled home, Please describe the accommodation when last settled:',\n",
    "        'Disabilities or Health Needs',\n",
    "       'The YP is Vulnerable because of:',\n",
    "       'Full Assessment of Eligibility',\n",
    "       'Before approaching St Basils, did the YP contact any of the following for help', 'Code',\n",
    "       'Description', 'EET Detail', 'Client No','Minutes Total','S_Start'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4df127d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Does the YP have a local Connection':'Local Connection','Accommodation Type (Tenure at time of application)':'Prev Accomodation'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c414e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237, 46)\n",
      "R=The distribution of classes is :\n",
      "Negative    824\n",
      "Positive    413\n",
      "Name: Result, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Client Number', 'Initial', 'Result', 'Gender', 'Preferred Language',\n",
       "       'Nationality', 'Do They Have Any Medical Issues',\n",
       "       'Is An Interpreter required', 'Local Connection', 'Prev Accomodation',\n",
       "       'A1', 'A2', 'B1', 'B2', 'C1', 'D1', 'E1', 'E2', 'F1', 'F2', 'F3', 'G1',\n",
       "       'H1', 'H3', 'I1', 'J1', 'K1', 'L1', 'TotalDisabilty',\n",
       "       'TotalMentalHealth', 'Marital Status', 'Sexual Orientation', 'Religion',\n",
       "       'Economic Status', 'EET status', 'Num Sessions', 'Time per Session',\n",
       "       'Minutes per week', 'Num Weeks', 'Ref_CN', 'Ref No', 'Service Type',\n",
       "       'Status', 'Area', 'Age at Start', 'Scheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now select the variables which are of most importance beacuse of their computation\n",
    "features_with_less_nan = []\n",
    "for feature in df.columns:\n",
    "    nan_percentage = np.round(df[feature].isnull().mean(), 4)\n",
    "    if(nan_percentage<0.5):\n",
    "        features_with_less_nan.append(feature)\n",
    "\n",
    "df1 = df[features_with_less_nan]\n",
    "print(df1.shape)\n",
    "print(\"R=The distribution of classes is :\")\n",
    "print(df1['Result'].value_counts())\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52255fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results here \n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_nas(df: pd.DataFrame):\n",
    "    if df.isnull().sum().sum() != 0:\n",
    "        na_df = (df.notnull().sum() / len(df)) * 100      \n",
    "        na_df = na_df.drop(na_df[na_df == 0].index).sort_values(ascending=False)\n",
    "        missing_data = pd.DataFrame({'Missing Ratio %' :na_df})\n",
    "        missing_data.plot(kind = \"barh\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No NAs found')\n",
    "plot_nas(df1)\n",
    "plot_width, plot_height = (24,18)\n",
    "plt.rcParams['figure.figsize'] = (plot_width,plot_height)\n",
    "plt.rcParams['font.size']=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e26d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuslts here \n"
     ]
    }
   ],
   "source": [
    "## Here we will check the features which have some nan values data\n",
    "#features_with_na=[features for features in df.columns if df[features].isnull().sum()>1]\n",
    "for feature in df1.columns:\n",
    "    print('Feature: {}  Missing: {}  Categories are {}'.format(feature,np.round(df1[feature].isnull().mean(), 4),len(df1[feature].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "257b7f25",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/737516756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65ed8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file to the datfiles raw folder\n",
    "df1.to_csv('/home/workspace/files/aryan/data_files_raw/eet_neet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f414ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
